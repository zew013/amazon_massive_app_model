{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18cd53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8da0119-6037-4e6a-a49a-0b137253d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from distill import *\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", truncation_side=\"left\")\n",
    "config = {\n",
    "        'vocab_size' : 30522 , # len(tokenizer.get_vocab())\n",
    "        'embedding_size' : 300,\n",
    "        'hidden_size' : 512,\n",
    "        'fc_size' : 128,\n",
    "        'num_layers' : 2,\n",
    "        'n_classes' : 60,\n",
    "        'dropout' : 0.5,\n",
    "        'epochs' : 40,\n",
    "        'lr' : 5e-4,\n",
    "        'temp' : 1,\n",
    "        'weight_decay' : 1e-4,\n",
    "        'alpha' : 0.95,\n",
    "        'batch_size' : 256,\n",
    "        'input_dir' : 'assets',\n",
    "        'dataset' : 'amazon',\n",
    "        'ignore_cache' : False,\n",
    "        'max_len' : 20,\n",
    "        'early_stop' : 3\n",
    "        }\n",
    "class AttributeDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config = AttributeDict(config)\n",
    "student_model = StudentModel(config)\n",
    "# Set the model to evaluation mode\n",
    "student_model.eval()\n",
    "\n",
    "# Load trained weights if available\n",
    "student_model.load_state_dict(torch.load('local_model.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "dummy_input_ids = torch.randint(\n",
    "    low=0,\n",
    "    high=config.vocab_size,\n",
    "    size=(2, config.max_len),\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "input_names = [\"input_ids\", \"attention_mask\"]\n",
    "output_names = [\"output_logits\"]\n",
    "\n",
    "# Export the model\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        student_model,                                   # Model to export\n",
    "        (dummy_input_ids, None),         # Model inputs as a tuple\n",
    "        \"student_model.onnx\",                            # Output file name\n",
    "        export_params=True,                              # Store the trained parameter weights inside the model file\n",
    "        opset_version=11,                                # ONNX version to export the model to\n",
    "        do_constant_folding=True,                        # Execute constant folding for optimization\n",
    "        input_names=input_names,                         # The model's input names\n",
    "        output_names=output_names,                       # The model's output names\n",
    "        dynamic_axes={                                   # Optional: specify dynamic axes\n",
    "            'input_ids': {0: 'batch_size'},\n",
    "            'attention_mask': {0: 'batch_size'},\n",
    "            'output_logits': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfecdbbf-305b-4f13-b604-ba7efc70a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Hello, how are you today?\",\n",
    "    \"I'm fine, thank you!\",\n",
    "    \"This is a longer sentence that might need truncation because it exceeds the maximum length.\"\n",
    "]\n",
    "\n",
    "# Tokenize the texts with padding and truncation\n",
    "encoded_inputs = tokenizer(\n",
    "    texts,\n",
    "    padding='max_length',  # Pad all sequences to max_length\n",
    "    truncation=True,       # Truncate sequences longer than max_length\n",
    "    max_length=20,         # Set the maximum length\n",
    "    return_tensors='np'    # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721a7d53-669b-4c10-85a5-7d43239b991d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101,  7592,  1010,  2129,  2024,  2017,  2651,  1029,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  1045,  1005,  1049,  2986,  1010,  4067,  2017,   999,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  2023,  2003,  1037,  2936,  6251,  2008,  2453,  2342,\n",
       "        19817,  4609, 10719,  2138,  2009, 23651,  1996,  4555,  3091,\n",
       "         1012,   102]]), 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2650b3-e535-4286-9e43-f0e141d820b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentModel(\n",
       "  (embedding): Embedding(30522, 300)\n",
       "  (rnn): LSTM(300, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=60, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import main\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784f22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e00525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikitext/wikitext-2-raw-v1 to C:/Users/Wang/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7ce0d605b44732a104381b39e85866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c56436a5d74ddc8a175c1c1db96c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a75eaa84e1446eb187ccce5cadf96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2d71a535ec47fc9f74ea4f8adf9214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikitext downloaded and prepared to C:/Users/Wang/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f640c9925ac4e93b7c4407b7dafcf4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wikitext\", 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498a24ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f42b5db251e46b99bbff14221a5d333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\v1\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Wang\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0e8086afe242a5bd01d093346b9fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba23215cfe746fb80db0834da204f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f01b546783f417eb5319de89e9bf93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d4b4b1aa3f4ba8a60e59248ea52017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623234b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ''}\n",
      "{'text': ' = Valkyria Chronicles III = \\n'}\n",
      "{'text': ''}\n",
      "{'text': ' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n'}\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in dataset['train']:\n",
    "    print(i)\n",
    "    c+=1\n",
    "    if c ==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "791a0025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The game \\'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer(dataset['train'][10]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d575195",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ' The game \\'s battle system , the BliTZ [MASK] , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81fe7d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2050894945859909,\n",
       "  'token': 5549,\n",
       "  'token_str': 'mode',\n",
       "  'sequence': 'the game\\'s battle system, the blitz mode, is carried over directly from valkyira chronicles. during missions, players select each unit using a top @ - @ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @ - @ person. a character can only act once per @ - @ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. each character has a field and distance of movement limited by their action gauge. up to nine characters can be assigned to a single mission. during gameplay, characters will call out if something happens to them, such as their health points ( hp ) getting low or being knocked out by enemy attacks. each character has specific \" potentials \", skills unique to each character. they are divided into \" personal potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" battle potentials \", which are grown throughout the game and always grant boons to a character. to learn battle potentials, each character has a unique \" masters table \", a grid @ - @ based skill table that can be used to acquire and link different skills. characters also have special abilities that grant them temporary boosts on the battlefield : kurt can activate \" direct command \" and move around the battlefield without depleting his action point gauge, the character reila can shift into her \" valkyria form \" and become invincible, while imca can target multiple enemy units with her heavy weapon.'},\n",
       " {'score': 0.02367718331515789,\n",
       "  'token': 2645,\n",
       "  'token_str': 'battle',\n",
       "  'sequence': 'the game\\'s battle system, the blitz battle, is carried over directly from valkyira chronicles. during missions, players select each unit using a top @ - @ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @ - @ person. a character can only act once per @ - @ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. each character has a field and distance of movement limited by their action gauge. up to nine characters can be assigned to a single mission. during gameplay, characters will call out if something happens to them, such as their health points ( hp ) getting low or being knocked out by enemy attacks. each character has specific \" potentials \", skills unique to each character. they are divided into \" personal potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" battle potentials \", which are grown throughout the game and always grant boons to a character. to learn battle potentials, each character has a unique \" masters table \", a grid @ - @ based skill table that can be used to acquire and link different skills. characters also have special abilities that grant them temporary boosts on the battlefield : kurt can activate \" direct command \" and move around the battlefield without depleting his action point gauge, the character reila can shift into her \" valkyria form \" and become invincible, while imca can target multiple enemy units with her heavy weapon.'},\n",
       " {'score': 0.020204229280352592,\n",
       "  'token': 2291,\n",
       "  'token_str': 'system',\n",
       "  'sequence': 'the game\\'s battle system, the blitz system, is carried over directly from valkyira chronicles. during missions, players select each unit using a top @ - @ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @ - @ person. a character can only act once per @ - @ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. each character has a field and distance of movement limited by their action gauge. up to nine characters can be assigned to a single mission. during gameplay, characters will call out if something happens to them, such as their health points ( hp ) getting low or being knocked out by enemy attacks. each character has specific \" potentials \", skills unique to each character. they are divided into \" personal potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" battle potentials \", which are grown throughout the game and always grant boons to a character. to learn battle potentials, each character has a unique \" masters table \", a grid @ - @ based skill table that can be used to acquire and link different skills. characters also have special abilities that grant them temporary boosts on the battlefield : kurt can activate \" direct command \" and move around the battlefield without depleting his action point gauge, the character reila can shift into her \" valkyria form \" and become invincible, while imca can target multiple enemy units with her heavy weapon.'},\n",
       " {'score': 0.02015605941414833,\n",
       "  'token': 4949,\n",
       "  'token_str': 'map',\n",
       "  'sequence': 'the game\\'s battle system, the blitz map, is carried over directly from valkyira chronicles. during missions, players select each unit using a top @ - @ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @ - @ person. a character can only act once per @ - @ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. each character has a field and distance of movement limited by their action gauge. up to nine characters can be assigned to a single mission. during gameplay, characters will call out if something happens to them, such as their health points ( hp ) getting low or being knocked out by enemy attacks. each character has specific \" potentials \", skills unique to each character. they are divided into \" personal potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" battle potentials \", which are grown throughout the game and always grant boons to a character. to learn battle potentials, each character has a unique \" masters table \", a grid @ - @ based skill table that can be used to acquire and link different skills. characters also have special abilities that grant them temporary boosts on the battlefield : kurt can activate \" direct command \" and move around the battlefield without depleting his action point gauge, the character reila can shift into her \" valkyria form \" and become invincible, while imca can target multiple enemy units with her heavy weapon.'},\n",
       " {'score': 0.01418268121778965,\n",
       "  'token': 3049,\n",
       "  'token_str': 'campaign',\n",
       "  'sequence': 'the game\\'s battle system, the blitz campaign, is carried over directly from valkyira chronicles. during missions, players select each unit using a top @ - @ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @ - @ person. a character can only act once per @ - @ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. each character has a field and distance of movement limited by their action gauge. up to nine characters can be assigned to a single mission. during gameplay, characters will call out if something happens to them, such as their health points ( hp ) getting low or being knocked out by enemy attacks. each character has specific \" potentials \", skills unique to each character. they are divided into \" personal potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" battle potentials \", which are grown throughout the game and always grant boons to a character. to learn battle potentials, each character has a unique \" masters table \", a grid @ - @ based skill table that can be used to acquire and link different skills. characters also have special abilities that grant them temporary boosts on the battlefield : kurt can activate \" direct command \" and move around the battlefield without depleting his action point gauge, the character reila can shift into her \" valkyria form \" and become invincible, while imca can target multiple enemy units with her heavy weapon.'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44183466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(encoded_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80a36d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 4.4084e-04, -2.6241e-01, -1.0192e-01,  ..., -6.2764e-02,\n",
       "           2.7584e-01,  3.7014e-01],\n",
       "         [ 7.2233e-01,  1.6449e-01,  4.0025e-01,  ...,  1.9161e-01,\n",
       "           4.0458e-01, -5.8094e-02],\n",
       "         [ 2.8198e-01, -1.7430e-01,  3.9076e-02,  ...,  2.7681e-02,\n",
       "           1.1886e-01,  9.1439e-01],\n",
       "         ...,\n",
       "         [ 6.8016e-01,  7.9712e-02,  8.3603e-01,  ..., -4.8959e-01,\n",
       "          -2.5017e-01, -2.3519e-01],\n",
       "         [ 3.8106e-02, -8.1751e-01, -3.4076e-01,  ...,  4.4815e-01,\n",
       "           9.6725e-02, -2.0311e-01],\n",
       "         [ 3.5750e-01,  1.9968e-01,  1.7437e-01,  ...,  1.5028e-01,\n",
       "          -2.3665e-01,  5.4391e-02]]], grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4b66dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[  101,  1996,  2208,  1005,  1055,  2645,  2291,  1010,  1996, 22312,\n",
       "           2291,  1010,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " \"The game 's battle system , the BliTZ system , \")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "text = str('The game \\'s battle system , the BliTZ system , ')\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90229e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[ 101, 5549, 1010,  102]]), 'attention_mask': tensor([[1, 1, 1, 1]])},\n",
       " 'mode , ')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = str('mode , ')\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8222dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b57222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import open as smart_open\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import io\n",
    "from dataloader import get_dataloader, check_cache, prepare_features, process_data, prepare_inputs\n",
    "from load import load_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10516df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://amazonmassive.s3.us-west-1.amazonaws.com/model.pt\n"
     ]
    }
   ],
   "source": [
    "load_path = \"https://amazonmassive.s3.us-west-1.amazonaws.com/model.pt\"\n",
    "print(load_path)\n",
    "with smart_open(load_path, 'rb') as f:\n",
    "    #buffer = io.BytesIO(f.read())\n",
    "    model=torch.load(io.BytesIO(f.read()),map_location=torch.device('cuda'))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", truncation_side=\"left\")\n",
    "\n",
    "# move elsewhere\n",
    "config = {\n",
    "        'vocab_size' : len(tokenizer.get_vocab()),\n",
    "        'embedding_size' : 300,\n",
    "        'hidden_size' : 512,\n",
    "        'fc_size' : 128,\n",
    "        'num_layers' : 2,\n",
    "        'n_classes' : 60,\n",
    "        'dropout' : 0.5,\n",
    "        'epochs' : 40,\n",
    "        'lr' : 5e-4,\n",
    "        'temp' : 1,\n",
    "        'weight_decay' : 1e-4,\n",
    "        'alpha' : 0.95,\n",
    "        'batch_size' : 256,\n",
    "        'input_dir' : 'assets',\n",
    "        'dataset' : 'amazon',\n",
    "        'ignore_cache' : False,\n",
    "        'max_len' : 20,\n",
    "        'early_stop' : 3\n",
    "        #'output_dir' : 'result',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6941cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62ed1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config = AttributeDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a441ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new input features ...\n",
      "exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: amazon_massive_intent/en\n",
      "Found cached dataset amazon_massive_intent (C:/Users/Wang/.cache/huggingface/datasets/mteb___amazon_massive_intent/en/1.0.0/a9ab9f5d309356e4995ca161846b3636f56df1ad43cb04bb300dd8b4f99141f4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cea0011685466686fca39592bd70a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'label', 'label_text', 'text'],\n",
      "        num_rows: 11514\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'label', 'label_text', 'text'],\n",
      "        num_rows: 2033\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'label', 'label_text', 'text'],\n",
      "        num_rows: 2974\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11514/11514 [00:03<00:00, 3077.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 4638, 10373, 2013, 2198, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]} {'id': '17180', 'label': 44, 'label_text': 'email_query', 'text': 'check email from john'}\n",
      "Number of train features: 11514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2033/2033 [00:00<00:00, 3121.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2054, 1005, 1055, 1996, 4769, 2005, 4074, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]} {'id': '17167', 'label': 17, 'label_text': 'email_querycontact', 'text': \"what's the address for alex\"}\n",
      "Number of validation features: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2974/2974 [00:00<00:00, 3162.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2038, 2198, 2741, 2033, 2019, 10373, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]} {'id': '17179', 'label': 44, 'label_text': 'email_query', 'text': 'has john sent me an email'}\n",
      "Number of test features: 2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache_results, already_exist = check_cache(config)\n",
    "\n",
    "if already_exist:\n",
    "    print('exist')\n",
    "    features = cache_results\n",
    "else:\n",
    "    print('not exist')\n",
    "    data = load_data()\n",
    "    features = prepare_features(config, data, tokenizer, cache_results)\n",
    "datasets = process_data(config, features, tokenizer)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55e2c9d7",
   "metadata": {},
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96db620e",
   "metadata": {},
   "source": [
    "inputs torch.Size([256, 20])\n",
    "rnn output size  (256 , 20 , 1024)\n",
    "rnn[:, -1, :] (256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d722c0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train data with 45 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.83it/s, loss=3.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | train losses 3.4368905120425755\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.06443679291687161 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.90it/s, loss=3.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train losses 3.264537196689182\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.12149532710280374 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.84it/s, loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train losses 2.9557895872328017\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.21790457452041317 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 45/45 [00:16<00:00,  2.76it/s, loss=2.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | train losses 2.6370142036014133\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.24938514510575505 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:16<00:00,  2.68it/s, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | train losses 2.3622832457224527\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.3512051155927201 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:16<00:00,  2.70it/s, loss=1.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | train losses 2.041533342997233\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.4171175602557796 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.19it/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 | train losses 1.7394599702623155\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.500245941957698 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.24it/s, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 | train losses 1.4498676538467408\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.5686178061977374 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.25it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 | train losses 1.1968798584408231\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.632070831283817 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.30it/s, loss=0.851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 | train losses 0.9731775787141588\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.6714215445154943 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.26it/s, loss=0.855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | train losses 0.809516433874766\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7092966060009838 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.14it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | train losses 0.6991011884477404\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7265125430398426 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.15it/s, loss=0.569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | train losses 0.577143837345971\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7427447122479095 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.17it/s, loss=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 | train losses 0.5005044963624742\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7530742744712248 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.20it/s, loss=0.424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 | train losses 0.42013916108343335\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7624200688637481 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:22<00:00,  2.01it/s, loss=0.423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 | train losses 0.39213339620166354\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7609444171175602 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:22<00:00,  2.01it/s, loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 | train losses 0.347553159793218\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.763895720609936 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.10it/s, loss=0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 | train losses 0.3044697874122196\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.764387604525332 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:22<00:00,  2.04it/s, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 | train losses 0.2840623355574078\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7722577471716675 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.18it/s, loss=0.275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 | train losses 0.2632052004337311\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7747171667486473 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:22<00:00,  2.04it/s, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 | train losses 0.2337894641690784\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7850467289719626 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.17it/s, loss=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 | train losses 0.22061460978455014\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7761928184948352 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.07it/s, loss=0.274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 | train losses 0.20605250861909655\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7771765863256271 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.14it/s, loss=0.212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 | train losses 0.20101119776566823\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.779636005902607 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.12it/s, loss=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 | train losses 0.18347965015305412\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.779636005902607 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.14it/s, loss=0.192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 | train losses 0.1725575155682034\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7816035415641909 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.20it/s, loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 | train losses 0.16072595781750149\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7860304968027545 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.42it/s, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 | train losses 0.18526800241735247\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7820954254795868 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.39it/s, loss=0.179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 | train losses 0.18337499830457898\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.780127889818003 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.32it/s, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 | train losses 0.16201074951224856\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7830791933103788 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.40it/s, loss=0.208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | train losses 0.15896476871437495\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7845548450565667 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.37it/s, loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 | train losses 0.15176246580150393\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.792916871618298 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.41it/s, loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 | train losses 0.1534287189443906\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7919331037875061 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.42it/s, loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 | train losses 0.1381225743227535\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7835710772257747 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.37it/s, loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 | train losses 0.12803749077849919\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7894736842105263 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.26it/s, loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 | train losses 0.11709917800294029\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7939006394490901 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.27it/s, loss=0.0931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 | train losses 0.11256734844711092\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7939006394490901 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:19<00:00,  2.34it/s, loss=0.088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 | train losses 0.10944215605656306\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7889818002951303 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 45/45 [00:22<00:00,  2.04it/s, loss=0.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 | train losses 0.11306494921445846\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.7939006394490901 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.25it/s, loss=0.0791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 | train losses 0.11444978747102949\n",
      "Loaded validation data with 8 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.794392523364486 |dataset split validation size: 2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'end of epochs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill.learn(config, model, datasets , tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d04f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentModel(\n",
       "  (embedding): Embedding(30522, 300)\n",
       "  (rnn): LSTM(300, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=60, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = distill.StudentModel(config)\n",
    "student_model.load_state_dict(torch.load('./saved_model/student.pt'))\n",
    "student_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecdb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4196de2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m CosineAnnealingWarmRestarts(\u001b[43moptimizer\u001b[49m, T_0, T_mult)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      3\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(student_model.parameters(), lr=config.lr, weight_decay = config.weight_decay)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult)\n",
    "for i in range(20):\n",
    "    scheduler.step()\n",
    "    scheduler.step(26)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4483f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = torch.randint(0, 5, size = (256 , 20 , 1024))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ceb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb86f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = torch.randint(1, 20, size = (256,))\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434135ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375009d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, -1, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = torch.nn.utils.rnn.pack_padded_sequence(a, length, batch_first=True, enforce_sorted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08cb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
