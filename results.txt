100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 720/720 [00:52<00:00, 13.62it/s]
validation acc: 0.8922774225282833 |dataset split validation size: 2033
epoch 7 | losses: 39.01720276102424
test acc: 0.8876933422999328 |dataset split test size: 2974





args = Namespace(task='custom',
                 temperature=0.7,
                 reinit_n_layers=0,
                 lldr=True,
                 head_lr = 0.00014,
                 init_lr = 0.00013,
                 head_decay = 0.01,
                 hidden_decay = 0.01,
                 scheduler_type='constant',
                 end_lr_ratio=-999999.0,
                 warmup_steps=0,
                 input_dir='assets',
                 output_dir='results',
                 model='bert',
                 seed=42,
                 dataset='amazon',
                 ignore_cache=False,
                 debug=False,
                 do_train=False,
                 do_eval=False,
                 batch_size=128,
                 learning_rate=0.0001,
                 
                 hidden_dim=10,
                 drop_rate=0.9,
                 embed_dim=10,
                 adam_epsilon=1e-08,
                 n_epochs=10,
                 max_len=20,
                 lr_decay_step=1,
                 lr_decay_gamma=1)
model, datasets, tokenizer = main.main(args)



Loading features from cache at assets\cache\amazon.pkl
train 11514
validation 2033
test 2974
Setting up bert model
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.57it/s]
validation acc: 0.05902606984751599 |dataset split validation size: 2033
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.96it/s]
test acc: 0.06893073301950235 |dataset split test size: 2974
Loaded train data with 90 batches
E:\anaconda\envs\v1\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
adamw llrd
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.06it/s, loss=3.12]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.11it/s]
validation acc: 0.2970978848991638 |dataset split validation size: 2033
epoch 0 | losses: 3.6997686200671724
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.07it/s, loss=2.19]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.64it/s]
validation acc: 0.5641908509591737 |dataset split validation size: 2033
epoch 1 | losses: 2.635628202226427
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.03it/s, loss=1.88]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.56it/s]
validation acc: 0.6345302508607968 |dataset split validation size: 2033
epoch 2 | losses: 1.986654363738166
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.10it/s, loss=1.36]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.64it/s]
validation acc: 0.6945400885391048 |dataset split validation size: 2033
epoch 3 | losses: 1.5590822829140558
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.14it/s, loss=1.17]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.01it/s]
validation acc: 0.736350221347762 |dataset split validation size: 2033
epoch 4 | losses: 1.2500273644924165
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.17it/s, loss=0.977]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.98it/s]
validation acc: 0.8042302016724053 |dataset split validation size: 2033
epoch 5 | losses: 1.027247083849377
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.17it/s, loss=0.795]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.61it/s]
validation acc: 0.8135759960649287 |dataset split validation size: 2033
epoch 6 | losses: 0.8781205773353576
100%|███████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.10it/s, loss=0.568]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.61it/s]
validation acc: 0.8283325135268077 |dataset split validation size: 2033
epoch 7 | losses: 0.7427343202961816
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.14it/s, loss=0.753]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.50it/s]
validation acc: 0.8440727988194786 |dataset split validation size: 2033
epoch 8 | losses: 0.5971539917919371
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.12it/s, loss=0.514]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.28it/s]
validation acc: 0.8406296114117069 |dataset split validation size: 2033
epoch 9 | losses: 0.5407301836543613
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.67it/s]
test acc: 0.8372562205783457 |dataset split test size: 2974




args = Namespace(task='custom',
                 temperature=0.7,
                 reinit_n_layers=0,
                 lldr=True,
                 head_lr = 0.00014,
                 init_lr = 0.00013,
                 head_decay = 0.01,
                 hidden_decay = 0.01,
                 scheduler_type='constant',
                 end_lr_ratio=-999999.0,
                 warmup_steps=0,
                 input_dir='assets',
                 output_dir='results',
                 model='bert',
                 seed=42,
                 dataset='amazon',
                 ignore_cache=False,
                 debug=False,
                 do_train=False,
                 do_eval=False,
                 batch_size=128,
                 learning_rate=0.0001,
                 
                 hidden_dim=10,
                 drop_rate=0.5,
                 embed_dim=10,
                 adam_epsilon=1e-08,
                 n_epochs=10,
                 max_len=20,
                 lr_decay_step=1,
                 lr_decay_gamma=1)
model, datasets, tokenizer = main.main(args)

Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.64it/s]
validation acc: 0.05902606984751599 |dataset split validation size: 2033
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 11.03it/s]
E:\anaconda\envs\v1\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
test acc: 0.06893073301950235 |dataset split test size: 2974
Loaded train data with 90 batches
adamw llrd
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.17it/s, loss=2.53]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.45it/s]
validation acc: 0.5213969503197246 |dataset split validation size: 2033
epoch 0 | losses: 3.161572085486518
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.17it/s, loss=1.62]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.45it/s]
validation acc: 0.5991146089522873 |dataset split validation size: 2033
epoch 1 | losses: 1.9529051661491394
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.18it/s, loss=1.26]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.73it/s]
validation acc: 0.6886374815543532 |dataset split validation size: 2033
epoch 2 | losses: 1.3670749545097352
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.20it/s, loss=1.01]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.91it/s]
validation acc: 0.7515986227250369 |dataset split validation size: 2033
epoch 3 | losses: 1.0449783510631985
100%|███████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.06it/s, loss=0.644]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.17it/s]
validation acc: 0.8145597638957206 |dataset split validation size: 2033
epoch 4 | losses: 0.8063751094871097
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.15it/s, loss=0.503]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.57it/s]
validation acc: 0.8106246925725529 |dataset split validation size: 2033
epoch 5 | losses: 0.6361798057953517
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.12it/s, loss=0.43]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.00it/s]
validation acc: 0.838170191834727 |dataset split validation size: 2033
epoch 6 | losses: 0.4904306968053182
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.12it/s, loss=0.194]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.31it/s]
validation acc: 0.8416133792424988 |dataset split validation size: 2033
epoch 7 | losses: 0.3882422892583741
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.14it/s, loss=0.262]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.94it/s]
validation acc: 0.8470241023118544 |dataset split validation size: 2033
epoch 8 | losses: 0.3060872705446349
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.13it/s, loss=0.335]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.37it/s]
validation acc: 0.8514510575504181 |dataset split validation size: 2033
epoch 9 | losses: 0.3075854503446155
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.66it/s]
test acc: 0.8426361802286483 |dataset split test size: 2974


args = Namespace(task='custom',
                 temperature=0.7,
                 reinit_n_layers=0,
                 lldr=True,
                 head_lr = 0.00031,
                 init_lr = 0.0003,
                 head_decay = 0.01,
                 hidden_decay = 0.01,
                 scheduler_type='constant',
                 end_lr_ratio=-999999.0,
                 warmup_steps=0,
                 input_dir='assets',
                 output_dir='results',
                 model='bert',
                 seed=42,
                 dataset='amazon',
                 ignore_cache=False,
                 debug=False,
                 do_train=False,
                 do_eval=False,
                 batch_size=128,
                 learning_rate=0.0001,
                 hidden_dim=10,
                 drop_rate=0.9,
                 embed_dim=10,
                 adam_epsilon=1e-08,
                 n_epochs=10,
                 max_len=20,
                 lr_decay_step=1,
                 lr_decay_gamma=1)
model, datasets, tokenizer = main.main(args)


Loading features from cache at assets\cache\amazon.pkl
train 11514
validation 2033
test 2974
Setting up bert model
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.00it/s]
validation acc: 0.05902606984751599 |dataset split validation size: 2033
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 11.10it/s]
test acc: 0.06893073301950235 |dataset split test size: 2974
Loaded train data with 90 batches
adamw llrd
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.18it/s, loss=3.12]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.27it/s]
validation acc: 0.2970978848991638 |dataset split validation size: 2033
epoch 0 | losses: 3.6997686200671724
100%|████████████████████████████████████████████████████████████████| 90/90 [00:31<00:00,  2.89it/s, loss=2.19]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.33it/s]
validation acc: 0.5641908509591737 |dataset split validation size: 2033
epoch 1 | losses: 2.635628202226427
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.04it/s, loss=1.88]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.16it/s]
validation acc: 0.6345302508607968 |dataset split validation size: 2033
epoch 2 | losses: 1.986654363738166
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.08it/s, loss=1.36]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.40it/s]
validation acc: 0.6945400885391048 |dataset split validation size: 2033
epoch 3 | losses: 1.5590822829140558
100%|████████████████████████████████████████████████████████████████| 90/90 [00:31<00:00,  2.88it/s, loss=1.17]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.12it/s]
validation acc: 0.736350221347762 |dataset split validation size: 2033
epoch 4 | losses: 1.2500273644924165
100%|███████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.01it/s, loss=0.977]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.07it/s]
validation acc: 0.8042302016724053 |dataset split validation size: 2033
epoch 5 | losses: 1.027247083849377
100%|███████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.17it/s, loss=0.795]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.07it/s]
validation acc: 0.8135759960649287 |dataset split validation size: 2033
epoch 6 | losses: 0.8781205773353576
100%|███████████████████████████████████████████████████████████████| 90/90 [00:33<00:00,  2.66it/s, loss=0.568]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.94it/s]
validation acc: 0.8283325135268077 |dataset split validation size: 2033
epoch 7 | losses: 0.7427343202961816
100%|███████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.00it/s, loss=0.753]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.56it/s]
validation acc: 0.8440727988194786 |dataset split validation size: 2033
epoch 8 | losses: 0.5971539917919371
100%|███████████████████████████████████████████████████████████████| 90/90 [00:32<00:00,  2.76it/s, loss=0.514]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.49it/s]
validation acc: 0.8406296114117069 |dataset split validation size: 2033
epoch 9 | losses: 0.5407301836543613
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.91it/s]
test acc: 0.8372562205783457 |dataset split test size: 2974



Loading features from cache at assets\cache\amazon.pkl
train 11514
validation 2033
test 2974
Setting up bert model
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.05it/s]
validation acc: 0.05902606984751599 |dataset split validation size: 2033
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.30it/s]
E:\anaconda\envs\v1\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
test acc: 0.06893073301950235 |dataset split test size: 2974
Loaded train data with 90 batches
init_lr 0.00013
head_lr 0.00014
adamw llrd
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.19it/s, loss=3.16]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.78it/s]
validation acc: 0.29217904574520415 |dataset split validation size: 2033
epoch 0 | losses: 3.710985477765401
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.13it/s, loss=2.42]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.57it/s]
validation acc: 0.5130349237579931 |dataset split validation size: 2033
epoch 1 | losses: 2.7909657425350614
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.05it/s, loss=2.24]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.71it/s]
validation acc: 0.5676340383669454 |dataset split validation size: 2033
epoch 2 | losses: 2.3978460523817273
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.05it/s, loss=2.22]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.86it/s]
validation acc: 0.5868175110673881 |dataset split validation size: 2033
epoch 3 | losses: 2.2027306980556913
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.14it/s, loss=1.96]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.86it/s]
validation acc: 0.5818986719134285 |dataset split validation size: 2033
epoch 4 | losses: 2.0938404811753166
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.13it/s, loss=2.01]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.33it/s]
validation acc: 0.5892769306443679 |dataset split validation size: 2033
epoch 5 | losses: 2.0285765210787456
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.14it/s, loss=1.99]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.45it/s]
validation acc: 0.6040334481062469 |dataset split validation size: 2033
epoch 6 | losses: 1.9734407663345337
100%|████████████████████████████████████████████████████████████████| 90/90 [00:28<00:00,  3.13it/s, loss=1.89]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.12it/s]
validation acc: 0.5951795376291196 |dataset split validation size: 2033
epoch 7 | losses: 1.9127556098832024
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.07it/s, loss=1.96]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.95it/s]
validation acc: 0.5863256271519921 |dataset split validation size: 2033
epoch 8 | losses: 1.8875169475873312
100%|████████████████████████████████████████████████████████████████| 90/90 [00:29<00:00,  3.03it/s, loss=1.79]
Loaded validation data with 16 batches
100%|███████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.55it/s]
validation acc: 0.5937038858829317 |dataset split validation size: 2033
epoch 9 | losses: 1.8718684871991476
Loaded test data with 24 batches
100%|███████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 11.09it/s]
test acc: 0.6005379959650302 |dataset split test size: 2974

